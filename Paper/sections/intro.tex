\section*{Introduction}
From nearly non-existence in the early 2000s, data breaches have exploded in terms of number of events and cumulative loss. As personal information has become the {\it ore} resource, mined by an Internet economy, which is largely based on targeted advertisement \cite{}, there shall be no surprise that criminals steal and exploit personal data in their own way, such as for identity frauds \cite{}. As people and organizations increasingly suffer their consequences, data breaches also undermine long-term confidence on the Internet as a reliable communication means, as a good place for trustworthy data storage, and as a place in which a decent level of privacy can be maintained.

The way people, organizations and governments shall view data breaches depends heavily on the risk they represent in terms of loss per event. In 2010, building on a dataset of 956 events, Maillart and Sornette showed that the distribution of severity, in terms of number of personal data loss per event, exhibited a power law tail distribution with an exponent $\mu \approx 0.7$ \cite{maillart2010}. With the information available at the time, the distribution was qualified of ``wild", according to Beno”t Mandelbrot, because neither its mean nor standard deviation were as a result of $\mu < 1$.

In the meantime, the number of records has been roughly multiplied by 10, with 9,576 exploitable events as of 31/10/2014. Also, the rate of events, as well as the cumulative loss, have tremendously accelerated (increased?) as shown on Figure \ref{dynamics}. We shall therefore re-define the nature of data breach risk in light of new information available, in order to outline a predictive model for a major extreme risk that has emerged less than 15 years ago.

After presenting the data (Section \ref{}), we determine the nature and the stability of the tail distribution using a novel approach \cite{}, combining the Generalized Extreme Value (GEV) \cite{} and the Generalized Pareto Distributions GPD) \cite{} theories (Section \ref{}),.We then analyze the exponential dynamics of events and cumulative loss, and how our understanding of the tail distribution helps establish a functional relation between the dynamics of events and loss (Section \ref{}). These results are crucial to model the return time of events of a given size. This {\it return-time} measures are typically used by civil engineers for designing infrastructures with a sufficient safety level to cope with large natural disasters, such as floods \cite{}, earthquakes \cite{}, hurricanes \cite{}, or by the insurance industry to calculate insurance premiums, capital reserves, and coverage limits. Similarly, {\it return-time} should be the cornerstone measures for designing sufficient safety measures to prevent cyber attacks, and to provision sufficient capital reserves to cope with a data breach event.
